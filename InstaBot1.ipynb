{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(executable_path = '/path/to/chormedriver')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "driver\n",
    "\n",
    "wait = WebDriverWait(driver,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 1 : \n",
    "Login to your Instagram Handle\n",
    "and Submit with sample username and password\n",
    "\n",
    "1] visting instagram,\n",
    "\n",
    "2] sending keys username and password,\n",
    "\n",
    "3] finding and clicking login button,\n",
    "\n",
    "4] suppresing the save info window,\n",
    "\n",
    "5] suppresing the turn on notification window,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.instagram.com/')\n",
    "driver.maximize_window()\n",
    "driver.implicitly_wait(8)\n",
    "\n",
    "smpl_user = \"sampleuser\"\n",
    "smpl_pswrd = \"samplepaswrd\"\n",
    "\n",
    "usrnm_box = driver.find_element(By.NAME,'username')\n",
    "usrnm_box.send_keys(smpl_user)\n",
    "\n",
    "pswrd_box = driver.find_element(By.NAME,'password')\n",
    "pswrd_box.send_keys(smpl_pswrd)\n",
    "time.sleep(2)\n",
    "\n",
    "# login button\n",
    "driver.find_element(By.XPATH,'//button[contains(@class, \"_aj1-\")]/div').submit()\n",
    "time.sleep(2)\n",
    "\n",
    "# will find the not now button on the particular page that will be asked for saving usrname and pswrd info\n",
    "driver.find_element(By.CLASS_NAME,'_ac8f').click()\n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element(By.CLASS_NAME, \"_a9_1\").click()\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 2 : Type for “food” in search bar and print all the names of the Instagram Handles that are displayed in list after typing “food”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "searching \"Food\" in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_text(txt):\n",
    "    search_button = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div[contains(@class,'x1xgvd2v')]/div[2]/div[2]\")))\n",
    "    search_button[0].click()\n",
    "\n",
    "    enter_txt = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//input[contains(@class,'_aauy')]\")))[0]\n",
    "    enter_txt.send_keys(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foodtalkindia\n",
      "food_lunatic\n",
      "indian_tasty_food\n",
      "caarafood\n",
      "food_stories_by_mishti\n",
      "dilsefoodie\n",
      "food\n",
      "indianfoodfreak\n",
      "foodiesince96\n",
      "gurgaonfoodblog\n",
      "omo.cafe\n",
      "delhifoodguide\n",
      "foodbloggerai\n",
      "foodie_incarnate\n",
      "foodhallindia\n",
      "kashmirfoodgram\n",
      "foodelhi\n",
      "foodiebyheart2.0\n",
      "delhifoodblogger\n",
      "reneechopra\n",
      "lost.and.hungry\n",
      "foodiesofindia\n",
      "thewickedsoul\n",
      "thisisdelhi\n",
      "imahimaagarwal\n",
      "mumbaifoodjunkie\n",
      "thepunefoodie\n",
      "foodzaggy\n",
      "phorumpandya\n",
      "food__junction\n",
      "gwaliorfoodsters\n",
      "foodiliciousmoments\n",
      "gurgaontimes.food\n",
      "foodiesafarii\n",
      "foodconnectindia\n",
      "food_feels\n",
      "delhieater\n",
      "gurugram_food_no.1\n",
      "indianfood_lovers\n",
      "delhifoodwalks\n",
      "foodieveggie\n",
      "komalchawlaofficial\n",
      "thegreatindianfoodie\n",
      "delishdirection\n",
      "foodportindia\n",
      "food52\n",
      "whaaatislife\n",
      "foodnetwork\n",
      "theglobalfoodie\n",
      "savorytales\n",
      "delhifoodnest\n"
     ]
    }
   ],
   "source": [
    "search_text(\"food\")    \n",
    "    # will give all the insta acc that are related to \"Food\"\n",
    "li = []\n",
    "for i in driver.find_elements(By.XPATH,'//a[contains(@class,\"x1yutycm\")]/div/div/div/div[2]/div/div/span'):\n",
    "    li.append(i.get_attribute(\"textContent\"))\n",
    "\n",
    "for i, string in enumerate(li):\n",
    "    if i % 2 != 1 and li[i][0] != \"#\":\n",
    "        print(string) \n",
    "      \n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 3: Searching and Opening a profile, \n",
    "Open profile of “So Delhi” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to clear the food text from the search bar\n",
    "clear_button = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME,\"_9-lv\")))\n",
    "clear_button[0].click()\n",
    "\n",
    "# now we will find account name \"So Delhi\"\n",
    "enter = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//input[contains(@class,'_aauy')]\")))[0]\n",
    "enter.send_keys(\"So Delhi\")\n",
    "driver.implicitly_wait(2)\n",
    "\n",
    "# now clicking over the \"So Delhi\" \n",
    "res = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//a[contains(@class,'x1qjc9v5')]/div/div/div/div[2]/div/div/span\")))[1].click()\n",
    "\n",
    "# time.sleep(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 4: Follow/Unfollow given handle:**  **\n",
    "    \n",
    "[1.] Open the Instagram Handle of “So Delhi”\n",
    "    \n",
    "[2.] Start following it. Print a message if you are already following\n",
    "    \n",
    "[3.] After following, unfollow the instagram handle. Print a message if you have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have unfollowed so delhi!!\n"
     ]
    }
   ],
   "source": [
    "# holding the follow button\n",
    "follow_button = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//button[contains(@class,'_aj1-')]\")))[0]\n",
    "\n",
    "# holding the value of following button\n",
    "following_button = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//button[contains(@class,'_aj1-')]\")))[0]\n",
    "\n",
    "# conditions will check whether the acc is followed or not \n",
    "if wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//button[contains(@class,'_aj1-')]\")))[0].get_attribute(\"textContent\") == 'Follow':\n",
    "    follow_button.click()\n",
    "    print(\"now you are following So Delhi!!\")\n",
    "    time.sleep(2)\n",
    "elif wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//button[contains(@class,'_aj1-')]\")))[0].get_attribute(\"textContent\")[0:9] == \"Following\":\n",
    "    following_button.click()\n",
    "    time.sleep(2)\n",
    "    if wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//span[contains(@class,'xvs91rp')]/span\")))[4].get_attribute(\"textContent\") == \"Unfollow\":\n",
    "       # holding the unfollow button \n",
    "       # unfollow button wil visible, when we click on following button means the new window will pop up after clicking on following button\n",
    "       wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//span[contains(@class,'xvs91rp')]/span\")))[4].click()\n",
    "       print(\"you have unfollowed so delhi!!\")\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task 5 : Like/Unlike posts::-->\n",
    "\n",
    "[1.]Liking the top 30 posts of the ‘dilsefoodie'.\n",
    "\n",
    "[2.]Print message if you have already liked it.\n",
    "\n",
    "[3.]Unliking the top 30 posts of the ‘dilsefoodie’.\n",
    "\n",
    "[4.]Print message if you have already unliked it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_text(\"dilsefoodie\")\n",
    "# dilsefoodie\n",
    "dilseFoodie = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div[contains(@class,'x9f619')]/div[contains(@class,'_abn_')]\")))\n",
    "dilseFoodie[0].click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it will scroll your page of insta handle\n",
    "driver.execute_script('window.scrollBy(0, 3000);')\n",
    "time.sleep(2.5)\n",
    "driver.execute_script('window.scrollBy(0, 3000);')\n",
    "time.sleep(2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "liking 30 posts of dilsefoodie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    # will locate your post \n",
    "    posts = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div[contains(@class,'x9f619')]/article[contains(@class,'x1iyjqo2')]/div/div/div[contains(@class,'_ac7v')]/div\")))\n",
    "    # posts\n",
    "\n",
    "    for i in range(30):\n",
    "        # will find and click over each n every post untill loop will break \n",
    "        posts[i].click()\n",
    "        # time.sleep(0.4)\n",
    "        \n",
    "        \n",
    "        like = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME,\"_aamw\")))\n",
    "        st = BeautifulSoup(like[0].get_attribute('innerHTML'),\"html.parser\").svg['aria-label']\n",
    "        # st    \n",
    "\n",
    "        if st == 'Like':\n",
    "            like[0].click()\n",
    "            # time.sleep(0.4)\n",
    "        \n",
    "        else:\n",
    "            print('You have already LIKED post NUMBER:',i+1)\n",
    "            # time.sleep(0.4)\n",
    "        \n",
    "        driver.back()\n",
    "        # time.sleep(0.4)\n",
    "except TimeoutException:\n",
    "    print('something went wrong!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNLIKE POST 30!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have already UNLIKED post NUMBER: 1\n",
      "You have already UNLIKED post NUMBER: 2\n",
      "You have already UNLIKED post NUMBER: 3\n",
      "You have already UNLIKED post NUMBER: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:    \n",
    "    # will locate your post \n",
    "    posts = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div[contains(@class,'x9f619')]/article[contains(@class,'x1iyjqo2')]/div/div/div[contains(@class,'_ac7v')]/div\")))\n",
    "    # posts\n",
    "\n",
    "    for i in range(30):\n",
    "        # will find and click over each n every post untill loop will break \n",
    "        posts[i].click()\n",
    "        # time.sleep(0.4)\n",
    "        \n",
    "        # will locate the unlike button and will click on it\n",
    "        unlike = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME,\"_aamw\")))\n",
    "        st = BeautifulSoup(unlike[0].get_attribute('innerHTML'),\"html.parser\").svg['aria-label']\n",
    "           \n",
    "\n",
    "        if st == 'Unlike':\n",
    "            unlike[0].click()\n",
    "            # time.sleep(0.4)\n",
    "        \n",
    "        else:\n",
    "            print('You have already UNLIKED post NUMBER:',i+1)\n",
    "            # time.sleep(0.4)\n",
    "        \n",
    "        driver.back()\n",
    "        # time.sleep(0.4)\n",
    "except TimeoutException:\n",
    "    print('something went wrong!')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6 : Extract list of followers,,,,,,\n",
    "\n",
    "[1]Extract the usernames of the first 500 followers of ‘foodtalkindia’ and ‘sodelhi’.\n",
    "\n",
    "[2]Now print all the followers of “foodtalkindia” that you are following but those who don’t follow you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_text('foodtalkindia') \n",
    "# time.sleep(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodtalkindia = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div[contains(@class,'x9f619')]/span[contains(@class,'x1lliihq')]/span/div\")))\n",
    "foodtalkindia[0].click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extraction of followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# it will extract the all followers and will store all the followers in a list named user\n",
    "def Extract_Followers():\n",
    "    try:\n",
    "        followers_but = wait.until(EC.presence_of_all_elements_located((By.XPATH,'//ul[contains(@class,\"x78zum5\")]/li[2]/a')))[0]\n",
    "        followers_but.click()\n",
    "        time.sleep(0.8)\n",
    "\n",
    "        frame = wait.until(EC.presence_of_element_located((By.CLASS_NAME,\"_aano\")))\n",
    "        for i in range(150):\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"arguments[0].scrollTop=arguments[0].scrollHeight\",frame)\n",
    "\n",
    "        names = []\n",
    "        x = wait.until(EC.presence_of_all_elements_located((By.XPATH,'//div[contains(@class,\"xt0psk2\")]/a/span')))\n",
    "        for i in x[:500]:\n",
    "            names.append(i.text.split('\\n')[0])\n",
    "        \n",
    "        return names\n",
    "    except TimeoutException:\n",
    "        print(\"Something went wrong!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing all 500 followers\n",
    "\n",
    "Note : there is something new on instagram or somekind of security dont know, i was unable to see all the followers \n",
    "only insta handler foodtalkindia can see there followers\n",
    "\n",
    "So i just printed all possible followers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 esmewhitney649509\n",
      "2 henry_haiyaz\n",
      "3 cathycooney75\n",
      "4 annikita90\n",
      "5 thecubbontable.foods\n",
      "6 aakritigulati\n",
      "7 aarcha_gm\n",
      "8 aasthaanandbajaj\n",
      "9 alsajrestaurant_\n",
      "10 yaragambalimut\n",
      "11 apoorvsharma91\n",
      "12 bass_kar_abhi\n",
      "13 chahat105338\n",
      "14 mandar_chef\n",
      "15 sahilkaushikkk\n",
      "16 passionate_foddie\n",
      "17 bigbose\n",
      "18 dietitian_tanyasharma\n",
      "19 eaglerestaurant1977\n",
      "20 frdeen.khan.501151\n",
      "21 jaborpune\n",
      "22 jasmiiinegupta\n",
      "23 kanish_vashisth\n",
      "24 kinni2112\n",
      "25 krsnam.bhatia\n",
      "26 wdymswbtg\n",
      "27 masoomshah87\n",
      "28 mamacholiya\n",
      "29 pancosgourmet\n",
      "30 payels_009\n",
      "31 boring_pandaa\n",
      "32 badcaptain0896\n",
      "33 rameshtahiliani\n",
      "34 modorimashita\n",
      "35 romibites\n",
      "36 s.k_1666\n",
      "37 sarita_devi1973\n",
      "38 sayeash\n",
      "39 shagun.roy14\n",
      "40 shivangi_pahwa\n",
      "41 shonalim\n",
      "42 sophia__choudhry66\n",
      "43 sudharsan87\n",
      "44 turk.pak.saray\n",
      "45 viral_vantage\n",
      "46 officlal_himanshu_hr76_\n",
      "47 while_i_am_on_earth\n",
      "48 simplyyy.bb\n",
      "49 cute____boy_0_143\n"
     ]
    }
   ],
   "source": [
    "# will print all the followers that are store in list named users\n",
    "users = Extract_Followers()\n",
    "ind = 1\n",
    "for username in users:\n",
    "    print(ind,username)\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Delhi all possible followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it will search so delhi \n",
    "search_text('So Delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it will find the so delhi and will click on it\n",
    "res = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//a[contains(@class,'x1qjc9v5')]/div/div/div/div[2]/div/div/span\")))[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 taruunn_\n",
      "2 j.s.r.93\n",
      "3 pranjalmeadh\n",
      "4 thememerpanti\n",
      "5 pawanluthra522\n",
      "6 gabaayush\n",
      "7 priyanshusingh114\n",
      "8 jatinarora.in\n",
      "9 deeptidua27\n",
      "10 smarth25\n",
      "11 shelly_9204\n",
      "12 ankita.luthra\n",
      "13 abhayofficial.00\n",
      "14 amit.misra.54\n",
      "15 simply.aishwarya_\n",
      "16 shubham.sr4\n",
      "17 nandini_choudhray\n",
      "18 shrishtisingh56\n",
      "19 jnagarajan88\n",
      "20 chefgautamkumar\n",
      "21 rsaeedakhan\n",
      "22 rakhiii07_\n",
      "23 cool_adroit\n",
      "24 shaziya_shahabuddin\n",
      "25 199poojagupta\n",
      "26 preeti4016singh\n",
      "27 bansal_anjali\n",
      "28 kaalecoatvala\n",
      "29 veersingh24557\n",
      "30 lalbharti\n",
      "31 mdsaifalisb\n",
      "32 hardik_ankita_8774\n",
      "33 bhawnagoyal1996\n",
      "34 priyak2031\n",
      "35 s_n_i_s_h_c_h_o_w\n",
      "36 vermanaaveen\n",
      "37 heyyzade\n",
      "38 egle_adyasan\n",
      "39 __spirit_guide\n",
      "40 sakshi19sabharwal\n",
      "41 preetisolanki604\n",
      "42 aaryavngupta\n",
      "43 anjubhaskarofficial\n",
      "44 swetaa_bhati\n",
      "45 preetigaddad\n",
      "46 poonamsingh8937\n",
      "47 rachnavashist\n",
      "48 _ayushman_chauhan_\n",
      "49 anshikagrwal\n",
      "50 aru.tuli\n",
      "51 shivansh._gupta\n",
      "52 uma.sachdeva\n",
      "53 walterjuniorsp\n",
      "54 imsubhashnagar\n",
      "55 saurabh_music_\n",
      "56 shreya_l\n",
      "57 pawan.panwar14\n",
      "58 rahulgupta_packwell\n",
      "59 rohit_rangbhara\n",
      "60 gaurav_raj258\n",
      "61 rakesh.cool.1983\n",
      "62 mohan_ram_s\n",
      "63 puri.monika\n",
      "64 _kishan_._singh\n",
      "65 official_shefali_rana_2878\n",
      "66 avi_khan9\n",
      "67 faizan_rehmani_official\n",
      "68 m.gupta04\n",
      "69 mahekashif\n",
      "70 chetanmosun\n",
      "71 iamhimanshukumar\n",
      "72 toosharchadha\n",
      "73 pvt.alisha07\n",
      "74 the_sun_bhola\n",
      "75 batra_the_explorer\n",
      "76 teva_lvr\n",
      "77 thefreesoul_rare\n",
      "78 ruchisharma11100\n",
      "79 sunilraidubai\n",
      "80 rayyann__r\n",
      "81 mansi.mns\n",
      "82 shivie.29\n",
      "83 nityasachdevaa\n",
      "84 me._.mike_\n",
      "85 an.unlike.human\n",
      "86 shubdhadhawan\n",
      "87 khoslasahib\n",
      "88 neetrajput1\n",
      "89 s_gumber_\n",
      "90 akshat.dubeyyy\n",
      "91 khadoossardar\n",
      "92 karishma__gulyani\n",
      "93 shradha_18viratian\n",
      "94 dr.deepak_kharb\n",
      "95 lavanyabishtt\n",
      "96 itsaadarshmohan\n",
      "97 anmolshant\n",
      "98 _vidya.bhojane_\n",
      "99 akul_luka\n",
      "100 jyoti1108\n",
      "101 zeba.wasi\n",
      "102 thesunrayyyy\n",
      "103 shriyabhatiame\n",
      "104 chopra.khushboo92\n",
      "105 simskalra5\n",
      "106 leogirl.123\n",
      "107 bit2u_\n",
      "108 aditya.pandian\n",
      "109 rama.krishna3338\n",
      "110 king_zeyaul\n",
      "111 dr.nandanisingh\n",
      "112 dr.sunitakaushal13\n",
      "113 jas_irat\n",
      "114 sonikabhati8\n",
      "115 no_nonsense_stuff\n",
      "116 sneharathor29\n",
      "117 zukosta\n",
      "118 radhe_p2711\n",
      "119 shallu.sharma.5437\n",
      "120 cutisicutipie\n",
      "121 minigambhir87\n",
      "122 naincy.nirwan\n",
      "123 kshitij.gundale\n",
      "124 ayushrastogi205\n",
      "125 bharti15285\n",
      "126 daleepkrbakaya\n",
      "127 aditi_kathuria24\n",
      "128 depak007dk\n",
      "129 damini_yadav90\n",
      "130 rinku9942\n",
      "131 sona11mathur\n",
      "132 neha6699\n",
      "133 vishwanimaria\n",
      "134 arshizaidi2022\n",
      "135 selcouth.pvt\n",
      "136 thesingh18\n",
      "137 _dikshant.jajoriya_\n",
      "138 prachisrivastava50\n",
      "139 shivani15mathur\n",
      "140 aayushkhattar_\n",
      "141 ihimanshuchaudhary\n",
      "142 ___iqra._\n",
      "143 leenapoddar20\n",
      "144 ajaykansal345\n",
      "145 meghameetahuja\n",
      "146 naveenbivera\n",
      "147 ryatnesh\n",
      "148 kaarigiri09\n",
      "149 imran_the_monster\n",
      "150 ansh.handa1208\n",
      "151 adhyamakkar\n",
      "152 abdur_xyz\n",
      "153 singhal_1202\n",
      "154 tanyaverma461\n",
      "155 ruchikajaroli\n",
      "156 archnaminz98\n",
      "157 trending.delhi\n",
      "158 iqra.khan7770\n",
      "159 nidhi_newar\n",
      "160 seemac737\n",
      "161 joshuajohn_312\n",
      "162 seemakhare13\n",
      "163 delhi.space\n",
      "164 samahacreation\n",
      "165 simratpalchahal\n",
      "166 mansiiuu\n",
      "167 vikkas96\n",
      "168 guptagaba\n",
      "169 ashasethi421\n",
      "170 iamdeepu_18\n",
      "171 shubhangi_roy04\n",
      "172 love2traveldude\n",
      "173 kundra_neha\n",
      "174 iam_ishapandit\n",
      "175 sakshimehra12\n",
      "176 alpna5636\n",
      "177 megha_haritwal_\n",
      "178 bhatiamitul\n",
      "179 jayantikasarwal\n",
      "180 shubh0691\n",
      "181 sachdevamadhur\n",
      "182 gauri.arora.73997\n",
      "183 mitawa.kamlesh\n",
      "184 lamin.sta\n",
      "185 bourn.vita81\n",
      "186 lysrii8\n",
      "187 __azharrrrr_______0008\n",
      "188 himanshugoyal2102\n",
      "189 doctor_16070\n",
      "190 kashishgarg___\n",
      "191 socialresellar_shop\n",
      "192 suru_zeeta\n",
      "193 sallopvt\n",
      "194 smita29tewari\n",
      "195 emshashank\n",
      "196 sowhatnowsomzz\n",
      "197 carsaaaaaaaaa\n",
      "198 dr.bagotiya_neeli\n",
      "199 raasha2408\n",
      "200 vanshmalhotra_777\n",
      "201 _alok_samadhiya_\n",
      "202 gaurrriiii__\n",
      "203 priyankaanshuljain\n",
      "204 _shamaila\n",
      "205 im_mohitsaini\n",
      "206 himaani_arora\n",
      "207 sakshi_29_\n",
      "208 saadkizindagi\n",
      "209 hiteshpaviya2019\n",
      "210 absolut_malan\n",
      "211 renujogpal\n",
      "212 anurag2123_\n",
      "213 abhi__nav012\n",
      "214 _sabila_nur._\n",
      "215 pratikshamishra6859\n",
      "216 jyoti8909\n",
      "217 mayankrastogi68\n",
      "218 sh1v1sm_21\n",
      "219 rahulsuperhunk\n",
      "220 jyotidhar16\n",
      "221 privlifeofkay._\n",
      "222 dee__pvt__\n",
      "223 vinay_asija\n",
      "224 cabysu\n",
      "225 srivastava_kr23\n",
      "226 renu0942\n",
      "227 that.alopeciagirl\n",
      "228 madhav.gupta20\n",
      "229 ig_ashish_0777\n",
      "230 vestrz\n",
      "231 shreyaagarwal999\n",
      "232 dishantkumarzzz\n",
      "233 its.sabazehrazaidi\n",
      "234 farhanaozair\n",
      "235 justbrands.in\n",
      "236 read.quickly\n",
      "237 ribeka00\n",
      "238 siddharth9043\n",
      "239 disguyshoot\n",
      "240 akanksha.rawat.980\n",
      "241 iakanchakamboj\n",
      "242 nameiskr1shna\n",
      "243 diamehta.13\n",
      "244 shubham_singhal07\n",
      "245 user192746492\n",
      "246 rimmm_malik\n",
      "247 yash_p_dahiya\n",
      "248 bhavyabali_\n",
      "249 nidhibhatia82\n",
      "250 dr.simrannegi_pt\n",
      "251 royal.jattni16\n",
      "252 seeyaa.____\n",
      "253 mahekkkf\n",
      "254 anjaliverma870\n",
      "255 vibha_jindal\n",
      "256 george_monalisa\n",
      "257 badalkushwah4235\n",
      "258 dreamz_5678\n",
      "259 its_vaibhavi08\n",
      "260 prernapahwaaa\n",
      "261 jyoti.aggarwal.5855\n",
      "262 ambika_vaish\n",
      "263 freak.pvtt\n",
      "264 nishkanxgallery\n",
      "265 deeppiikka\n",
      "266 fatima_alvi__\n",
      "267 khushalll.18\n",
      "268 wanderlust_love5\n",
      "269 mahajan_samriti_\n",
      "270 ______nano_____\n",
      "271 mybearpaws\n",
      "272 ichchha_goyal\n",
      "273 inzimam_99\n",
      "274 qudrat_qazi\n",
      "275 tapasyxx_.17\n",
      "276 roy_priyatama9\n",
      "277 vyashii\n",
      "278 charumehta09\n",
      "279 tarasinghji\n",
      "280 swativish_06\n",
      "281 dahiya6465\n",
      "282 nirmalarchna\n",
      "283 saritasawhney0001\n",
      "284 saisha.gaba14\n",
      "285 surbi_sharmaa\n",
      "286 _.harshii_25\n",
      "287 arunakatyal2102\n",
      "288 86vic\n",
      "289 navyasurana\n",
      "290 leafybat9\n",
      "291 shaurya_bhardwaj10\n",
      "292 dear_delhi_delhiiites\n",
      "293 paul.man21\n",
      "294 sach_fact908\n",
      "295 naimdiwan55\n",
      "296 mishti_adi23\n",
      "297 gauravsharma3559\n",
      "298 a_madhav\n",
      "299 meayeshahussain\n",
      "300 ayushiaggarwal94\n",
      "301 deepak.sapra.1297\n",
      "302 snapbot.co.in\n",
      "303 rizwan_pathaan123\n",
      "304 bornto6369\n",
      "305 d_humble_bulletier\n",
      "306 radhika.khosla\n",
      "307 rohit_soni_official2001\n",
      "308 pankajjoshi0014\n",
      "309 rachnakaushik\n",
      "310 prakashtalra\n",
      "311 lydiamerlinjoseph2066\n",
      "312 throughsimran\n",
      "313 dushyantarora\n",
      "314 iamaakashgupta_\n",
      "315 cocobaeofficial\n",
      "316 dusht_daman\n",
      "317 singal_asha\n",
      "318 dr.jashan_kamboj\n",
      "319 saanvii.i\n",
      "320 froodfunofficial\n",
      "321 hiteshwadhwa01\n",
      "322 rdvxnn\n",
      "323 mayank_singh_the_dreamer\n",
      "324 utkrsa_gupta\n",
      "325 shwetamandal\n",
      "326 salmankhan___0786\n",
      "327 ustatkamya\n",
      "328 karanhandoo\n",
      "329 jankariwalaofficial\n",
      "330 dheerajsingh_30\n",
      "331 shwetanegi74\n",
      "332 supratheesh\n",
      "333 the_trappedemoticon\n",
      "334 vaarijaavan07\n",
      "335 mayabaswal\n",
      "336 abhishekknagpal\n",
      "337 kavita.suhag_1000\n",
      "338 vaishaliarora08\n",
      "339 tarakcards__\n",
      "340 shibanimajumdar\n",
      "341 the__mishra\n",
      "342 neelamgeragera\n",
      "343 shubhwhoo\n",
      "344 cheshtaanandsharma\n",
      "345 glitters_note\n",
      "346 amit_jaggi_27\n",
      "347 shubhi.jain.184\n",
      "348 vighnesh12\n",
      "349 harleensandhu21_\n",
      "350 imshkrsrvstv\n",
      "351 tarinijindal\n",
      "352 _krittika.roy_\n",
      "353 sonia0935\n",
      "354 shikha_sr18\n",
      "355 tamanna_chauhan1\n",
      "356 syed_imam67\n",
      "357 vertikasetia\n",
      "358 shrenikeshri\n",
      "359 yashika_phul\n",
      "360 shilps_shine_aster\n",
      "361 shobhitkumar42\n",
      "362 aligavinash\n",
      "363 dhakuriagirl\n",
      "364 msgposts\n",
      "365 pooja__1014\n",
      "366 its_awaissk.official\n",
      "367 sagarflair\n",
      "368 nagpal5192\n",
      "369 jaanvi_20_\n",
      "370 namann_b\n",
      "371 s.sanidhya\n",
      "372 saloni__2812\n",
      "373 gouravsinghjadon_\n",
      "374 akshaysharma7423\n",
      "375 gunjannn.3\n",
      "376 janvigera\n",
      "377 guptasushmitadas\n",
      "378 art_house999\n",
      "379 ak3107ash\n",
      "380 somi_khan10\n",
      "381 theoutdoorsys\n",
      "382 __ashutoshsharma\n",
      "383 _shwetakatheria\n",
      "384 ymeenu909\n",
      "385 vishiiii__\n",
      "386 kohli.neha27\n",
      "387 shakeel945ahmed\n",
      "388 adityakuagrawal\n",
      "389 manvigarg_18\n",
      "390 sudhirspall\n",
      "391 vj_vaishalijain\n",
      "392 manishaambwani\n",
      "393 parul_nischal\n",
      "394 organic_abhishek\n",
      "395 sapan_mohini\n",
      "396 vijayamrutraj2\n",
      "397 dripping_dose\n",
      "398 url.aayush\n",
      "399 smartchoiceacademyinsta\n",
      "400 perfect_man_baadsha\n",
      "401 ansari_sahab_019\n",
      "402 priyanka.munjal.5\n",
      "403 nirali0905\n",
      "404 tarini.bhasin\n",
      "405 miss._.qureshi1\n",
      "406 sonali558\n",
      "407 saini_aman17\n",
      "408 bornrider06\n",
      "409 leo_messi_shubh\n",
      "410 diptigulia\n",
      "411 i_m_avinxsh\n",
      "412 jeswinjames18\n",
      "413 tyrant_1o1\n",
      "414 ayaans2812\n",
      "415 itshansikaaa\n",
      "416 naziafarhin25\n",
      "417 _khwaish92\n",
      "418 amitabhasin\n",
      "419 _gunjanaswal22_\n",
      "420 dessertsoul603\n",
      "421 han.dsomeboy21\n",
      "422 dawarharshita\n",
      "423 shubham_kholi24\n",
      "424 abhay__aru\n",
      "425 sanjusharma9910\n",
      "426 anshhjatana\n",
      "427 meeraamawat\n",
      "428 kohli9760\n",
      "429 rao_sahab_lalit\n",
      "430 gargamishi\n",
      "431 vkgautam2\n",
      "432 vaishalibisht646\n",
      "433 bubbersimmi\n",
      "434 thetravelingclatt\n",
      "435 huehuehuerushu\n",
      "436 _hetroublemaker_\n",
      "437 jassi.sawhney2101\n",
      "438 pvt_bhumi_1234\n",
      "439 paras_yadav_14\n",
      "440 rashmichauhaniit\n",
      "441 anurag.gupta.37\n",
      "442 ashifacool786\n",
      "443 dr.deepti_art_conservator\n",
      "444 praneyaaa\n",
      "445 tanvi_2752\n",
      "446 monimridul\n",
      "447 sast_abazar123\n",
      "448 ameen_afthal\n",
      "449 paawani.narang\n",
      "450 _chitra_shukla1111\n",
      "451 devansh.nation\n",
      "452 nandini.agarwal.334491\n",
      "453 jyotirughwani\n",
      "454 malvikaraj_4\n",
      "455 payalbhatoa\n",
      "456 _shubham_sid_\n",
      "457 thisisdheeraj__\n",
      "458 priyanka123.ntpc\n",
      "459 foundhrithik\n",
      "460 wdymswbtg\n",
      "461 gautam_manisha_\n",
      "462 piaswindow\n",
      "463 __nadia.hussain__\n",
      "464 tushargarg7228\n",
      "465 kulraaj24\n",
      "466 actuallyaditya_\n",
      "467 malay_agrawal\n",
      "468 anuuushkaaaa_\n",
      "469 dr.alvin_benoyyy\n",
      "470 __guleena_nayyar._\n",
      "471 sumitravelvlog\n",
      "472 shanu_mr.perfection\n",
      "473 om_swahaa\n",
      "474 kanicabakshi\n",
      "475 raveen510\n",
      "476 sshubhamguptaa\n",
      "477 itspri_official\n",
      "478 chetan_108_96_kuli\n",
      "479 walia9805\n",
      "480 sharma.akshika\n",
      "481 d.introverted.sag\n",
      "482 varshuakku9599\n",
      "483 harshit_tiwari.07\n",
      "484 jain_manushi31\n",
      "485 pranavdograa\n",
      "486 angeldeeksha1\n",
      "487 drimkunsh\n",
      "488 arbaz_ansari0001\n",
      "489 ria20sid\n",
      "490 chinmayyyjainnn\n",
      "491 niits05\n",
      "492 poorva095\n",
      "493 arppitamarora\n",
      "494 meenakshi.xoxo\n",
      "495 i_vishal_bisht\n",
      "496 xpanky123\n",
      "497 alongwithadarsh\n",
      "498 harshita.bhandari.98\n",
      "499 sumit_0507\n",
      "500 ritikaritzi\n"
     ]
    }
   ],
   "source": [
    "# according to the extract_followers \n",
    "# it will find all possible followers and will append all of them into a list \n",
    "# and will print each of them one by one\n",
    "users = Extract_Followers()\n",
    "ind = 1\n",
    "for username in users:\n",
    "    print(ind,username)\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "printing all the followers of 'foodtalkindia' that you are following but those who don't follow you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_text('foodtalkindia')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodtalkindia = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div[contains(@class,'x9f619')]/span[contains(@class,'x1lliihq')]/span/div\")))\n",
    "foodtalkindia[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #locating following button and click on it\n",
    "    followers_btn = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME,\"_ac2a\")))\n",
    "    followers_btn[2].click()\n",
    "        \n",
    "    frame = wait.until(EC.presence_of_element_located((By.CLASS_NAME,\"_aano\")))\n",
    "    for i in range(20):\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"arguments[0].scrollTop=arguments[0].scrollHeight\",frame)\n",
    "\n",
    "    # x holding the value of insta handler follow/following button      \n",
    "    x = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div[contains(@class,'x9f619')]/div/div[3]/div/button/div\")))\n",
    "    \n",
    "    # y holding the insta handler names those are being followed by user\n",
    "    y = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div[contains(@class,'xt0psk2')]/a/span/div\")))\n",
    "\n",
    "    count = 0\n",
    "    j = 0\n",
    "    li = []\n",
    "    for i in x:\n",
    "        if i.get_attribute('textContent') == 'Following':\n",
    "            # will append the attribute of those user who is followed by user but they dont follow user\n",
    "            li.append(y[j].get_attribute('textContent'))\n",
    "            j+=1\n",
    "        else:\n",
    "            count+=1\n",
    "    \n",
    "except TimeoutException:\n",
    "    print(\"Somethinf went wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total handler :  324\n",
      "Total Accounts those are being followed by user : 3\n",
      "1 instagramVerified\n",
      "2 official_youmee\n",
      "3 meetumendiratta\n"
     ]
    }
   ],
   "source": [
    "# accounts those are followed by user, they dont follow user\n",
    "print(\"Total handler : \",count+j)\n",
    "print(\"Total Accounts those are being followed by user who don's follow the user:\",j)\n",
    "ind = 1\n",
    "for i in li:\n",
    "    print(ind,i)\n",
    "    ind+=1\n",
    "driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taks 7 : Check the story of ‘coding.ninjas’. Consider the following \n",
    "\n",
    "Scenarios and print error messages accordingly -\n",
    "\n",
    "If You have already seen the story.\n",
    "\n",
    "Or The user has no story.\n",
    "\n",
    "Or View the story if not yet seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching coding ninjas in search bar \n",
    "search_text('coding.ninjas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the coding ninjas profile\n",
    "coding_Ninja = wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div[contains(@class,'x9f619')]/span[contains(@class,'x1lliihq')]/span/div\")))\n",
    "coding_Ninja[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have not seen the story yet! The story will be shown to you now. check out the driver window\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    # it will check whether the height of the element is okay to see story\n",
    "    if int( wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div[contains(@class,'_aarf')]/canvas\")))[0].get_attribute('height'))==210:\n",
    "        # it will print the messege if there is no story or u have not seen the story yet\n",
    "        print('You have not seen the story yet! The story will be shown to you now. check out the driver window')\n",
    "        # it will fint he element and click over the button and the stroy seciton of that particular acc will be open\n",
    "        wait.until(EC.presence_of_all_elements_located((By.XPATH,'//div[contains(@class, \"_aarf\")]')))[0].click()\n",
    "    elif int( wait.until(EC.presence_of_all_elements_located((By.XPATH,\"//div[contains(@class,'_aarf')]/canvas\")))[0].get_attribute('height'))==208:\n",
    "        # if u have been already watched the story before it will throw a messege \n",
    "        print('You have already seen the story!')\n",
    "except NoSuchElementException:\n",
    "    print(\"there is no stroy uploaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thank you had a great fun while doing this \n",
    "# code by - Atharva Prajapati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
